Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
12000,1.4189383,22.013409961685824,0.0650796,1.2015354758031995,1.2015354758031995,1.0
24000,1.4157399,23.092369477911646,0.051131,1.3090360949795887,1.3090360949795887,1.0
36000,1.4045432,27.014018691588785,0.1578925,1.70116815444465,1.70116815444465,1.0
48000,1.3923831,33.679190751445084,0.30794847,2.3708092553078095,2.3708092553078095,1.0
60000,1.3754416,45.55813953488372,0.5325273,3.549224996751593,3.549224996751593,1.0
72000,1.3600286,70.94011976047904,0.85141575,6.093413904041587,6.093413904041587,1.0
84000,1.3480483,159.28,1.2840705,14.886668939590454,14.886668939590454,1.0
96000,1.3416572,387.8125,1.750551,36.18750527128577,36.18750527128577,1.0
108000,1.3379339,660.6666666666666,2.283141,64.80556530422635,64.80556530422635,1.0
